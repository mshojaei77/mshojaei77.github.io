# Attention Mechanisms

self-attention, multi-head attention, scaled dot-product attention, cross-attention, causal attention 