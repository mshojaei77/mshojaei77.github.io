---
title: "Part 1: The Foundations"
nav_order: 1
has_children: true
permalink: /book/part1-foundations/
---

# Part 1: The Foundations ğŸ”

**ğŸ¯ Focus:** Core ML concepts, neural networks, traditional models, tokenization, embeddings, transformers  
**ğŸ“ˆ Difficulty:** Beginner to Intermediate  
**ğŸ“ Outcome:** Solid foundation in ML/NLP fundamentals and transformer architecture

**ğŸ¯ Learning Objectives:** Build essential knowledge through hands-on implementation, starting with neural network fundamentals, understanding the evolution from traditional language models to transformers, and mastering tokenization, embeddings, and the transformer architecture.

## Chapters in This Part

1. [Neural Networks Foundations for LLMs](01_neural_networks.md)
2. [Traditional Language Models](02_traditional_language_models.md)  
3. [Tokenization](03_tokenization.md)
4. [Embeddings](04_embeddings.md)
5. [The Transformer Architecture](05_transformer_architecture.md)

---

**Prerequisites Check:**
- [ ] **Python (4/5 required)**: Classes, decorators, async/await, context managers
- [ ] **Linear Algebra (3/5 required)**: Matrix operations, eigenvalues, SVD
- [ ] **Probability & Statistics (3/5 required)**: Distributions, Bayes' theorem, hypothesis testing
- [ ] **Calculus (2/5 required)**: Derivatives, chain rule, gradients 