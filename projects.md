# Projects and Publications

My comprehensive collection of research, development projects, and educational resources that I've created, focusing on Large Language Models (LLMs), Natural Language Processing, and AI applications. This repository showcases my practical implementations, theoretical foundations, and production-ready solutions for modern AI systems that I've developed over time.

## 📚 Core LLM Foundations

### Prerequisites

#### 💻 Interactive Notebooks:
- **[🟠 Linear Algebra Fundamentals for LLMs (Colab)](https://colab.research.google.com/drive/1nCNL7Ro5vOPWS5yaqTMpz2B056TyjsHy?usp=sharing)** - This notebook will guide you through the essential linear algebra concepts required for understanding Large Language Models (LLMs). We'll cover vectors, matrices, and basic operations using NumPy, with a focus on their application within the attention mechanism.
- **[🟠 Probability and Statistics for LLMs (Colab)](https://colab.research.google.com/drive/1oFu5ZL0AUlxDU8xhygr-datwEnHS9JVN)** - This notebook provides an in-depth exploration of probability concepts foundational to Large Language Models (LLMs), combining theoretical explanations with real-world examples and code implementations in PyTorch.
- **[🟠 GPU Essentials for LLMs (Colab)](https://colab.research.google.com/drive/1S-LwgyO_bmS135nJmJxm1ZKVlpv9Acfv)** - This Jupyter Notebook tutorial explores the crucial role of GPUs (Graphics Processing Units) in powering Large Language Models (LLMs). You'll learn why GPUs are essential, how they accelerate AI workloads, and the latest advancements in GPU technology.

### 1. [Tokenization](Tutorial/Tokenization.md)
Text preprocessing, BPE, WordPiece, SentencePiece, multilingual tokenization

#### 📄 Publications:
- **[Introduction to Tokenization: A Theoretical Perspective](https://medium.com/@mshojaei77/introduction-to-tokenization-a-theoretical-perspective-b1cc22fe98c5)**
- **[Understanding BPE Tokenization](https://medium.com/@mshojaei77/understanding-bpe-tokenization-a-hands-on-tutorial-80570314b12f)**
- **[Fast Tokenizers: How Rust is Turbocharging NLP](https://medium.com/@mshojaei77/fast-tokenizers-how-rust-is-turbocharging-nlp-dd12a1d13fa9)**

#### 💻 Interactive Notebooks:
- **[🟠 Tokenization Techniques (Interactive Colab)](https://colab.research.google.com/drive/1RwrtINbHTPBSRIoW8Zn9BRabxXguRRf0?usp=sharing)**
- **[🟠 GPT Tokenizer Implementation (Colab)](https://colab.research.google.com/drive/1y0KnCFZvGVf_odSfcNAws6kcDD7HsI0L?usp=sharing)**
- **[🟠 Tokenizer Comparison (Colab)](https://colab.research.google.com/drive/1wVSCBGFm7KjJy-KugYGYETpncWsPgx5N?usp=sharing)**
- **[🟠 Hugging Face Tokenizers (Colab)](https://colab.research.google.com/drive/1mcFgQ9PX1TFyEAsFOnoS1ozeSz3vM6A1?usp=sharing)**
- **[🟠 Build and Push a Tokenizer (Colab)](https://colab.research.google.com/drive/1uYFoxwCKwshkchBgQ4y4z9cDfKRlwZ-e?usp=sharing)**
- **[🟠 New Tokenizer Training (Colab)](https://colab.research.google.com/drive/1452WFn66MZzYylTNcL6hV5Zd45sskzs7?usp=sharing)**
- **[🟠 Compare Tokenizers Performance (Colab)](https://colab.research.google.com/drive/1-g4LJkbkHnIOKxcpcxlcXOaC4iU3yQ-6?usp=sharing)**
- **[🟠 Tokenization BPE (Colab)](https://colab.research.google.com/drive/1BcGWiBCv8ntFjtLbyPQzzsVNTeB-OWd4?usp=sharing)**
- **[🟠 Tokenizer Training (Colab)](https://colab.research.google.com/drive/1grpYJpb69-OqybpAsHfBsLRBIqC5gPjo?usp=sharing)**
- **[🟠 Tokenizing with Different Methods (Colab)](https://colab.research.google.com/drive/1necyJp2QExr0hVEH5X5vKhpPTZt277Lq?usp=sharing)**
- **[🟠 Persian BPE Tokenizer (Colab)](https://colab.research.google.com/drive/1fbiNoPIsGN8lymEXBvH63nKqNHYh_AG5?usp=sharing)**
- **[🟠 Persian Gemma Tokenizer (Colab)](https://colab.research.google.com/drive/1hqWGJQZKctOPk25zSFkfn5WLMmtbouJI?usp=sharing)**
- **[🟠 Train Llama Tokenizer (Colab)](https://colab.research.google.com/drive/1io3lfNNz7cJfH_SO9eRqJxWufG3W-5AK?usp=sharing)**

#### 🤗 Persian Tokenizers:
- **[PersianBPETokenizer](https://huggingface.co/mshojaei77/PersianBPETokenizer)** - BPE tokenizer optimized for Persian text
- **[PersianGemmaTokenizerFast](https://huggingface.co/mshojaei77/PersianGemmaTokenizerFast)** - Fast tokenizer for Persian Gemma models
- **[PersianWordPieceTokenizer](https://huggingface.co/mshojaei77/PersianWordPieceTokenizer)** - WordPiece tokenizer for Persian language
- **[PersianUnigramTokenizer](https://huggingface.co/mshojaei77/PersianUnigramTokenizer)** - Unigram-based tokenizer for Persian
- **[PersianLlamaTokenizerFast](https://huggingface.co/mshojaei77/PersianLlamaTokenizerFast)** - Fast tokenizer for Persian Llama models

### 2. [Embeddings](Tutorial/Embeddings.md)
Word2Vec, GloVe, BERT, contextual embeddings, semantic search, multimodal embeddings

#### 📄 Publications:
- **[Word Embeddings Deep Dive](https://medium.com/@mshojaei77/from-words-to-vectors-a-gentle-introduction-to-word-embeddings-eaadb1654778)**
- **[Contextual Embedding Guide](https://medium.com/@mshojaei77/beyond-one-word-one-meaning-contextual-embeddings-187b48c6fc27)**
- **[Sentence Embedding Techniques](https://medium.com/@mshojaei77/beyond-words-mastering-sentence-embeddings-for-semantic-nlp-dc852b1382ba)**

#### 💻 Interactive Notebooks:
- **[🟠 Interactive Word2Vec Tutorial](https://colab.research.google.com/drive/1dVkCRF0RKWWSP_QQq79LHNYGhead14d0?usp=sharing)**
- **[🟠 Embedding Techniques (Colab)](https://colab.research.google.com/drive/1EsafsnpONd7VI2hlTRJ0PYjrTmvSTA8x?usp=sharing)**
- **[🟠 Pre-trained Embeddings (Colab)](https://colab.research.google.com/drive/1pPB-7ZIzyJ88SR83DqGUZKLHj4y4TAHy?usp=sharing)**
- **[🟠 Traditional Word Embedding (Colab)](https://colab.research.google.com/drive/1ufvWaTDL0lK2tyTwdRBnXouHIMjBiKBC?usp=sharing)**
- **[🟠 Train a Word2Vec Model (Colab)](https://colab.research.google.com/drive/1xxH3Ak6ycH6UITpFytac7JHEJTj__eiX?usp=sharing)**
- **[🟠 Word Embeddings (Colab)](https://colab.research.google.com/drive/1yu0JxtCn5cYBFeTrCPeheSG0p9zRnxYR?usp=sharing)**

### 3. [Neural Networks](Tutorial/Neural_Networks.md)
Backpropagation, activation functions, optimization, regularization, mixed precision training


### 4. [Traditional Language Models](Tutorial/Traditional_LMs.md)
N-gram models, RNNs, LSTMs, GRUs, sequence-to-sequence models, attention mechanisms

#### 📄 Publications:
- **[Understanding Language Models](https://medium.com/@mshojaei77/1ac0e05ca1f3)**

#### 💻 Interactive Notebooks:
- **[🟠 Intro to Large Language Models (Colab)](https://colab.research.google.com/drive/1HGqq9dKb-JlAgw0gdUhSmTKf-0v9Xq1Y?usp=sharing)**
- **[🟠 Understanding Large Language Models (Colab)](https://colab.research.google.com/drive/1wmHSypXDmiAhb1SgjLZR2wJDRj34lb4L?usp=sharing)**

### 5. [Transformers](Tutorial/Transformers.md)
Self-attention, multi-head attention, positional encodings, decoder-only architecture

### 6. [Data Preparation](Tutorial/Data_Preparation.md)
Data collection, web scraping, cleaning, deduplication, quality assessment, synthetic data generation

#### 💻 Interactive Notebooks:
- **[🟠 Dataset Merge (Colab)](https://colab.research.google.com/drive/1BT8o8mkD4iwMC9zxSlMvtTivLxHSvbDV?usp=sharing)**
- **[🟠 Dataset Merger Simple (Colab)](https://colab.research.google.com/drive/1eKw9gOqRanXntb1azv4bWOx7pIlvaMDn?usp=sharing)**
- **[🟠 Dataset Merger Speech (Colab)](https://colab.research.google.com/drive/1e_dIgQae3Hy-FJjObVbAG8gJHgbHPvUf?usp=sharing)**
- **[🟠 Noise Reduction Test (Colab)](https://colab.research.google.com/drive/10aCNn6ICV3J4MpYfP7RnK8q4qUBi65ZW?usp=sharing)**
- **[🟠 EEG Artifact Detection (Colab)](https://colab.research.google.com/drive/1DkJ3Yyfep9qGHDc9G245OgwIvCSlRCR9?usp=sharing)**

#### 🚀 Open Source Projects:
- **[AdvancedWebScraper](https://github.com/mshojaei77/AdvancedWebScraper)** - Comprehensive web scraping tool with versatile data extraction capabilities
- **[Prompt-Scraper](https://github.com/mshojaei77/Prompt-Scraper)** - Effortlessly collect and transform Midjourney prompts into LM datasets
- **[Youtube2Book](https://github.com/mshojaei77/Youtube2Book)** - Extract transcripts from YouTube videos and structure with AI
- **[Word-Frequency-Analyzer](https://github.com/mshojaei77/Word-Frequency-Analyzer)** - Analyze word frequency in monthly news data
- **[pytsetmc-api](https://github.com/mshojaei77/pytsetmc-api)** - Python client for Tehran Stock Exchange Market Center data retrieval
- **[langchain_crawler](https://github.com/mshojaei77/langchain_crawler)** - Web crawling implementation using LangChain

## 🧪 Model Training & Fine-Tuning

### 7. [Pre-Training](Tutorial/Pre_Training.md)
Unsupervised pre-training, causal language modeling, distributed training, scaling laws

### 8. [Post-Training Datasets](Tutorial/Post_Training_Datasets.md)
Instruction datasets, chat templates, conversation formatting, synthetic data generation

#### 📄 Publications:
- **[RAG vs. CAG vs. Fine-Tuning: Which Brain Boost Does Your LLM Actually Need?](https://medium.com/@mshojaei77/rag-vs-cag-vs-fine-tuning-which-brain-boost-does-your-llm-actually-need-b1234567890a)**

#### 💻 Interactive Notebooks:
- **[🟠 Persian SFT Formattings (Colab)](https://colab.research.google.com/drive/1S-LwgyO_bmS135nJmJxm1ZKVlpv9Acfv?usp=sharing)**
- **[🟠 CAG (Cache-Augmented Generation) (Colab)](https://colab.research.google.com/drive/1-EIO5M6zeQgTd715PKCk-XK9odfEgOZY?usp=sharing)**

### 9. [Supervised Fine-Tuning](Tutorial/Supervised_Fine_Tuning.md)
LoRA, QLoRA, PEFT, instruction tuning, domain adaptation, model merging

#### 📄 Publications:
- **[The LoRA Cookbook: Fine-Tuning Large Language Models for Everyone](https://medium.com/@mshojaei77/the-lora-cookbook-fine-tuning-large-language-models-for-everyone-a1234567890a)**

#### 💻 Interactive Notebooks:
- **[🟠 Fine-tune Mistral-7b with QLoRA](https://colab.research.google.com/drive/1o_w0KastmEJNVwT5GoqMCciH-18ca5WS?usp=sharing)**
- **[🟠 LazyMergekit](https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing)**
- **[🟠 LazyAxolotl](https://colab.research.google.com/drive/1TsDKNo2riwVmU55gjuBgB1AXVtRRfRHW?usp=sharing)**
- **[🟠 AutoQuant](https://colab.research.google.com/drive/1b6nqC7UZVt8bx4MksX7s656GXPM-eWw4?usp=sharing)**
- **[🟠 Model Family Tree](https://colab.research.google.com/drive/1s2eQlolcI1VGgDhqWIANfkfKvcKrMyNr?usp=sharing)**
- **[🟠 ZeroSpace](https://colab.research.google.com/drive/1LcVUW5wsJTO2NGmozjji5CkC--646LgC)**
- **[🟠 AutoAbliteration](https://colab.research.google.com/drive/1RmLv-pCMBBsQGXQIM8yF-OdCNyoylUR1?usp=sharing)**
- **[🟠 AutoDedup](https://colab.research.google.com/drive/1o1nzwXWAa8kdkEJljbJFW1VuI-3VZLUn?usp=sharing)**
- **[🟠 Fine-tune LLMs with Axolotl (Colab)](https://colab.research.google.com/drive/134SeMeoVCT0Sh-iRHlJ6wb_JBApspbkN?usp=sharing)**
- **[🟠 OpenAI GPT-4o Fine-tuning (Colab)](https://colab.research.google.com/drive/12ZRobn4GHPHLWuefJ4JYoX3TEhwXBM-T?usp=sharing)**
- **[🟠 GRPO Fine-tune (Colab)](https://colab.research.google.com/drive/155cGUY1kLOtb7b0ycHdW7cZbaK3na856?usp=sharing)**
- **[🟠 Llama 1B GRPO Training (Colab)](https://colab.research.google.com/drive/15o_Grw4PGnVNj03uAaB2Juctil_ADy_g?usp=sharing)**
- **[🟠 Qwen GRPO Training (Colab)](https://colab.research.google.com/drive/18HV_LDfIEq5NUApKpduVGdLxTGaEmNDK?usp=sharing)**
- **[🟠 Mergekit (Colab)](https://colab.research.google.com/drive/19k6DRX3h2_s1J7VwQl3fJKx-q5jrd7a_?usp=sharing)**
- **[🟠 Merge Parameters (Colab)](https://colab.research.google.com/drive/1tPIPqKL_pUrxTst-7X59-EyXVCK-z6Rm?usp=sharing)**
- **[🟠 Gemma SFT (Colab)](https://colab.research.google.com/drive/1fF4iPcBDoq4W-8z1eq53dA4VcZcXqF_W?usp=sharing)**
- **[🟠 Gemma3 4B (Colab)](https://colab.research.google.com/drive/1AbHtKyeyuZSZBEwrAbgfTyc4Fee7smQB?usp=sharing)**
- **[🟠 Gemma3 4B Persian (Colab)](https://colab.research.google.com/drive/1ENgkVdgO9AOtBRFq0Vykctgazpk2wvcL?usp=sharing)**
- **[🟠 Gemma3 4B Persian v2 (Colab)](https://colab.research.google.com/drive/1fiSXbawfI-EMvntaV81ORDnjKDKZhzAl?usp=sharing)**
- **[🟠 Persian Gemma3 4B (Colab)](https://colab.research.google.com/drive/1gSeiaY5NcL51q0CZCbDCsPXt2DDhPFaS?usp=sharing)**
- **[🟠 Qwen2.5 7B Alpaca (Colab)](https://colab.research.google.com/drive/1GRl5QMsQL56pB4O49jnPr_KA0uxam02E?usp=sharing)**
- **[🟠 SFT (Supervised Fine-Tuning) (Colab)](https://colab.research.google.com/drive/1tdPUEUQb97HkNObhQD8YsJ1zy4sGAPjU?usp=sharing)**
- **[🟠 GGUF Maker (Colab)](https://colab.research.google.com/drive/1gw4QwKABzwJgVzs91_lEUW5R0y_GFz52?usp=sharing)**

### 10. [Preference Alignment](Tutorial/Preference_Alignment.md)
RLHF, DPO, reward modeling, Constitutional AI, safety evaluation

### 11. [Model Architectures](Tutorial/Model_Architecture_Variants.md)
Mixture of Experts, state space models, Mamba, RWKV, long context architectures

### 12. [Reasoning](Tutorial/Reasoning.md)
Chain-of-Thought, tree-of-thoughts, process reward models, test-time compute scaling

#### 📄 Publications:
- **[How AI Learns to Fix Own Mistakes](https://medium.com/@mshojaei77/how-ai-learns-to-fix-own-mistakes-a1234567890a)**

### 13. [Evaluation](Tutorial/Evaluation.md)
Benchmarking, MMLU, GSM8K, HumanEval, human evaluation, bias testing

## 🚀 Production & Deployment

### 14. [Quantization](Tutorial/Quantization.md)
Post-training quantization, quantization-aware training, GGUF, INT4/INT8 quantization

### 15. [Inference Optimization](Tutorial/Inference_Optimization.md)
Flash Attention, KV cache, speculative decoding, high-throughput inference

#### 📄 Publications:
- **[Understanding the Differences Between CPU, GPU, TPU, and LPU](https://medium.com/@mshojaei77/understanding-the-differences-between-cpu-gpu-tpu-and-lpu-a1234567890a)**

#### 🚀 Open Source Projects:
- **[vram-calculator](https://github.com/mshojaei77/vram-calculator)** - Calculate VRAM requirements for LLMs and recommend suitable GPUs

### 16. [Model Enhancement](Tutorial/Model_Enhancement.md)
Context window extension, model merging, knowledge distillation, continual learning

### 17. [Security & Responsible AI](Tutorial/Securing_LLMs.md)
OWASP LLM Top 10, prompt injection, jailbreaking, bias detection, privacy protection

### 18. [Running LLMs](Tutorial/Running_LLMs.md)
API integration, local deployment, production servers, streaming responses

#### 📄 Publications:
- **[Guide to Deploying Qwen 3 with vLLM on RunPod](https://medium.com/@mshojaei77/guide-to-deploying-qwen-3-with-vllm-on-runpod-a1234567890a)**

#### 🚀 Open Source Projects:
- **[ollama-desktop](https://github.com/mshojaei77/ollama-desktop)** - Powerful desktop application for interacting with local AI models
- **[ollama_gui](https://github.com/mshojaei77/ollama_gui)** - User-friendly Qt desktop application for Ollama backend
- **[SubTrans-Ollama](https://github.com/mshojaei77/SubTrans-Ollama)** - Simple tool for translating movie subtitles (.srt) files
- **[ChatGPT-Desktop-App](https://github.com/mshojaei77/ChatGPT-Desktop-App)** - Interactive desktop app with document uploads and conversation management
- **[OpenRouterChatApp](https://github.com/mshojaei77/OpenRouterChatApp)** - Simple chat application using OpenRouter API
- **[GPT-Translator](https://github.com/mshojaei77/GPT-Translator)** - Streamlit translation app using advanced language models
- **[Pdf-Finder-Telegram-bot](https://github.com/mshojaei77/Pdf-Finder-Telegram-bot)** - Search for book PDFs in Telegram bot
- **[healthcare-assistant](https://github.com/mshojaei77/healthcare-assistant)** - Healthcare chat interface for emotional support and stress analysis

## 🤖 Applications & Systems

### 19. [RAG](Tutorial/RAG.md)
Retrieval Augmented Generation, vector databases, Graph RAG, conversational RAG

#### 🚀 Open Source Projects:
- **[ollama_rag](https://github.com/mshojaei77/ollama_rag)** - Fully local RAG system using Ollama and FAISS
- **[open-notebook](https://github.com/mshojaei77/open-notebook)** - AI-powered knowledge management and question-answering system
- **[TalkWithWeb](https://github.com/mshojaei77/TalkWithWeb)** - Customizable AI chatbot with personalized knowledge base
- **[DataSpeakGPT](https://github.com/mshojaei77/DataSpeakGPT)** - Read files and images and retrieve data for LLM
- **[Cortex](https://github.com/mshojaei77/Cortex)** - Advanced AI Deep Scholar Researcher Agent with RAG and Milvus integration
- **[RAG-Agent](https://github.com/mshojaei77/RAG-Agent)** - RAG implementation with LangChain and LangGraph libraries
- **[RAG_CAG_SFT](https://github.com/mshojaei77/RAG_CAG_SFT)** - Educational overview of RAG, Cache-Augmented Generation, and SFT techniques

### 20. [Agents](Tutorial/Agents.md)
Function calling, tool usage, multi-agent systems, autonomous task execution

#### 🚀 Open Source Projects:
- **[ReActMCP](https://github.com/mshojaei77/ReActMCP)** - Reactive MCP client for real-time web search insights **(141⭐)**
- **[EasyMCP](https://github.com/mshojaei77/EasyMCP)** - Beginner-friendly client for Model Context Protocol
- **[Groogle](https://github.com/mshojaei77/Groogle)** - Groq + Google integration for enhanced search capabilities
- **[GoogleGPT](https://github.com/mshojaei77/GoogleGPT)** - Combine Google search with ChatGPT capabilities
- **[simple_function_calling](https://github.com/mshojaei77/simple_function_calling)** - Beginner tutorial on connecting LLMs to external tools
- **[SuperAgent](https://github.com/mshojaei77/SuperAgent)** - Advanced agent implementation
- **[SuperNova-Desktop](https://github.com/mshojaei77/SuperNova-Desktop)** - Desktop agent application

### 21. [Multimodal](Tutorial/Multimodal.md)
Vision-language models, text-to-image generation, audio processing, document understanding

#### 💻 Interactive Notebooks:
- **[🟠 Whisper Turbo (Colab)](https://colab.research.google.com/drive/1yf3WiqyjpO9LcC0LV48CWotOl4Sv4ngQ?usp=sharing)**
- **[🟠 Whisper Turbo FP32 Async (Colab)](https://colab.research.google.com/drive/1xS2bMCt6acvaWdeT_r8gtnole3bSFjG3?usp=sharing)**
- **[🟠 Maestro Qwen2.5 VL JSON Extraction (Colab)](https://colab.research.google.com/drive/1Ia_rCRcVUqBcKGNS_8HTYtzy3OZ9Mo1k?usp=sharing)**
- **[🟠 XTTS Test on Long Text (Colab)](https://colab.research.google.com/drive/1xXOnvsuTqdZiAb9Mzqpe_MRBD4FlbCr2?usp=sharing)**

#### 🚀 Open Source Projects:
- **[Text2Prompt2Image](https://github.com/mshojaei77/Text2Prompt2Image)** - Flask app using Mixtral-8x7B & Playground-v2 for text-to-image generation
- **[flux_local](https://github.com/mshojaei77/flux_local)** - Lightweight toolkit for running FLUX.1-schnell text-to-image models locally

### 22. [LLMOps](Tutorial/LLMOps.md)
Model versioning, CI/CD pipelines, monitoring, deployment strategies, cost optimization

---

# 📊 Datasets & Resources

## 🇮🇷 Persian Language Resources

### 📚 Persian Language Datasets:
- **[PersianCorpus_merged](https://huggingface.co/mshojaei77/PersianCorpus_merged)** - Massive Persian corpus with 14.7M records **(38 downloads)**
- **[PersianTelegramChannels](https://huggingface.co/mshojaei77/PersianTelegramChannels)** - Persian Telegram channels dataset with 12.1k records **(74 downloads)**
- **[persian-document-corpus](https://huggingface.co/mshojaei77/persian-document-corpus)** - Persian document corpus with 13.1k records **(31 downloads)**
- **[persian_blogs](https://huggingface.co/mshojaei77/persian_blogs)** - Persian blog posts dataset with 27.4k records **(28 downloads)**
- **[persian-tweets-2024](https://huggingface.co/mshojaei77/persian-tweets-2024)** - Persian tweets from 2024 with 900 records **(23 downloads)**
- **[persian-search-queries](https://huggingface.co/mshojaei77/persian-search-queries)** - Persian search queries dataset with 1.31k records **(27 downloads)**

### 📊 Persian Instruction Datasets:
- **[Persian_sft](https://huggingface.co/mshojaei77/Persian_sft)** - Persian supervised fine-tuning dataset with 681k records **(59 downloads)**
- **[Persian_sft_jsonl](https://huggingface.co/mshojaei77/Persian_sft_jsonl)** - Persian SFT in JSONL format with 681k records **(26 downloads)**
- **[Persian_sft_QA](https://huggingface.co/mshojaei77/Persian_sft_QA)** - Persian SFT Q&A format with 681k records **(33 downloads)**
- **[merged_persian_alpaca](https://huggingface.co/mshojaei77/merged_persian_alpaca)** - Persian Alpaca-style instruction dataset with 527k records **(21 downloads)**
- **[merged_persian_sharegpt](https://huggingface.co/mshojaei77/merged_persian_sharegpt)** - Persian ShareGPT format dataset with 527k records **(17 downloads)**
- **[Persian_lmsys_QA](https://huggingface.co/mshojaei77/Persian_lmsys_QA)** - Persian LMSYS Q&A dataset with 5.43k records **(59 downloads)**
- **[alpaca_persian_telegram](https://huggingface.co/mshojaei77/alpaca_persian_telegram)** - Persian Alpaca with Telegram data, 1k records **(17 downloads)**

### 📊 Persian Evaluation Datasets:
- **[multiple-choice-persian-eval](https://huggingface.co/mshojaei77/multiple-choice-persian-eval)** - Persian multiple-choice evaluation dataset with 364 records **(20 downloads)**
- **[SCED](https://huggingface.co/mshojaei77/SCED)** - Specialized evaluation dataset with 32 records **(18 downloads)**

### 🎵 Persian Audio Datasets:
- **[persian_tts_merged](https://huggingface.co/mshojaei77/persian_tts_merged)** - Persian TTS dataset with 82.2k records **(60 downloads)**
- **[farsi_asr_merged](https://huggingface.co/mshojaei77/farsi_asr_merged)** - Persian ASR dataset **(12 downloads, Private)**

## 🌐 Multi-Language & Specialized Datasets

### 🌐 Multi-Language Instruction Datasets:
- **[Dolly_Alpaca_Lmsys](https://huggingface.co/mshojaei77/Dolly_Alpaca_Lmsys)** - Merged instruction dataset with 1.07M records **(26 downloads)**
- **[merged_mental_health_dataset](https://huggingface.co/mshojaei77/merged_mental_health_dataset)** - Mental health support dataset with 868k records **(26 downloads)**

### 📚 Educational Datasets:
- **[ielts-practice-sentences](https://huggingface.co/mshojaei77/ielts-practice-sentences)** - IELTS practice sentences with 45.7k records **(24 downloads)**

### 🎨 Creative Datasets:
- **[Midjourney-Art-Prompts](https://huggingface.co/mshojaei77/Midjourney-Art-Prompts)** - Curated collection of Midjourney art prompts **(3 records)**

---

# 🤖 Persian LLM Models

## 🔥 Featured Models:
- **[gemma-3-4b-persian-v0](https://huggingface.co/mshojaei77/gemma-3-4b-persian-v0)** - Persian fine-tuned Gemma-3 4B model **(1.74K downloads)**
- **[gemma-2-2b-fa-v2](https://huggingface.co/mshojaei77/gemma-2-2b-fa-v2)** - Persian Gemma-2 2B model v2 **(21 downloads)**
- **[Gemma-2-2b-fa](https://huggingface.co/mshojaei77/Gemma-2-2b-fa)** - Persian Gemma-2 2B model **(13 downloads)**
- **[persian_phi-3](https://huggingface.co/mshojaei77/persian_phi-3)** - Persian fine-tuned Phi-3 model **(Private)**

## 🎯 Specialized Variants:
- **[gemma-3-4b-persian-lora-adaptors](https://huggingface.co/mshojaei77/gemma-3-4b-persian-lora-adaptors)** - LoRA adapters for Persian Gemma-3 **(9 downloads)**
- **[gemma-3-4b-persian-v0-abliterated](https://huggingface.co/mshojaei77/gemma-3-4b-persian-v0-abliterated)** - Abliterated version for uncensored responses **(6 downloads)**
- **[gemma-3-4b-persian-v0-abliterated-Q8_0-GGUF](https://huggingface.co/mshojaei77/gemma-3-4b-persian-v0-abliterated-Q8_0-GGUF)** - Quantized GGUF format **(11 downloads)**

---

# 🌟 Community & Learning Resources

## 📚 Learning Platforms

### 🎯 Curated Collections:
- **[Awesome-AI](https://github.com/mshojaei77/Awesome-AI)** - Best AI resources, tools, samples, and demos **(124⭐)**
- **[Awesome-Prompts](https://github.com/mshojaei77/Awesome-Prompts)** - Ready-to-use prompts for productivity and creativity

### 📚 Educational Resources:
- **[LLMs-Journey](https://github.com/mshojaei77/LLMs-Journey)** - Progress tracking with code, projects, and notes
- **[ML-Journey](https://github.com/mshojaei77/ML-Journey)** - Machine Learning journey with hands-on projects
- **[Python-Course](https://github.com/mshojaei77/Python-Course)** - Teaching materials from Kazerun University course



---

# 📊 Impact & Metrics

| **Platform** | **Metric** | **Value** |
|-------------|------------|-----------|
| 🤗 Hugging Face | Model Downloads | 1.8K+ |
| 🤗 Hugging Face | Dataset Downloads | 500+ |
| 🐙 GitHub | Total Stars | 600+ |
| 📄 Medium | Article Views | 100K+ |
| 🟠 Colab | Notebook Runs | 10K+ |
| 👥 GitHub | Followers | 184 |
| 🤗 Hugging Face | Followers | 52 |

---

# 🔗 Connect

- **📧 Email:** [shojaei.dev@gmail.com](mailto:shojaei.dev@gmail.com)
- **💼 LinkedIn:** [mshojaei77](https://www.linkedin.com/in/mshojaei77)
- **🐙 GitHub:** [mshojaei77](https://github.com/mshojaei77)
- **🤗 Hugging Face:** [mshojaei77](https://huggingface.co/mshojaei77)
