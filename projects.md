# Projects and Publications

My comprehensive collection of research, development projects, and educational resources that I've created, focusing on Large Language Models (LLMs), Natural Language Processing, and AI applications. This repository showcases my practical implementations, theoretical foundations, and production-ready solutions for modern AI systems that I've developed over time.

## ğŸ“š Core LLM Foundations

### Prerequisites

#### ğŸ’» Interactive Notebooks:
- **[ğŸŸ  Linear Algebra Fundamentals for LLMs (Colab)](https://colab.research.google.com/drive/1nCNL7Ro5vOPWS5yaqTMpz2B056TyjsHy?usp=sharing)** - This notebook will guide you through the essential linear algebra concepts required for understanding Large Language Models (LLMs). We'll cover vectors, matrices, and basic operations using NumPy, with a focus on their application within the attention mechanism.
- **[ğŸŸ  Probability and Statistics for LLMs (Colab)](https://colab.research.google.com/drive/1oFu5ZL0AUlxDU8xhygr-datwEnHS9JVN)** - This notebook provides an in-depth exploration of probability concepts foundational to Large Language Models (LLMs), combining theoretical explanations with real-world examples and code implementations in PyTorch.
- **[ğŸŸ  GPU Essentials for LLMs (Colab)](https://colab.research.google.com/drive/1S-LwgyO_bmS135nJmJxm1ZKVlpv9Acfv)** - This Jupyter Notebook tutorial explores the crucial role of GPUs (Graphics Processing Units) in powering Large Language Models (LLMs). You'll learn why GPUs are essential, how they accelerate AI workloads, and the latest advancements in GPU technology.

### 1. [Tokenization](Tutorial/Tokenization.md)
Text preprocessing, BPE, WordPiece, SentencePiece, multilingual tokenization

#### ğŸ“„ Publications:
- **[Introduction to Tokenization: A Theoretical Perspective](https://medium.com/@mshojaei77/introduction-to-tokenization-a-theoretical-perspective-b1cc22fe98c5)**
- **[Understanding BPE Tokenization](https://medium.com/@mshojaei77/understanding-bpe-tokenization-a-hands-on-tutorial-80570314b12f)**
- **[Fast Tokenizers: How Rust is Turbocharging NLP](https://medium.com/@mshojaei77/fast-tokenizers-how-rust-is-turbocharging-nlp-dd12a1d13fa9)**

#### ğŸ’» Interactive Notebooks:
- **[ğŸŸ  Tokenization Techniques (Interactive Colab)](https://colab.research.google.com/drive/1RwrtINbHTPBSRIoW8Zn9BRabxXguRRf0?usp=sharing)**
- **[ğŸŸ  GPT Tokenizer Implementation (Colab)](https://colab.research.google.com/drive/1y0KnCFZvGVf_odSfcNAws6kcDD7HsI0L?usp=sharing)**
- **[ğŸŸ  Tokenizer Comparison (Colab)](https://colab.research.google.com/drive/1wVSCBGFm7KjJy-KugYGYETpncWsPgx5N?usp=sharing)**
- **[ğŸŸ  Hugging Face Tokenizers (Colab)](https://colab.research.google.com/drive/1mcFgQ9PX1TFyEAsFOnoS1ozeSz3vM6A1?usp=sharing)**
- **[ğŸŸ  Build and Push a Tokenizer (Colab)](https://colab.research.google.com/drive/1uYFoxwCKwshkchBgQ4y4z9cDfKRlwZ-e?usp=sharing)**
- **[ğŸŸ  New Tokenizer Training (Colab)](https://colab.research.google.com/drive/1452WFn66MZzYylTNcL6hV5Zd45sskzs7?usp=sharing)**
- **[ğŸŸ  Compare Tokenizers Performance (Colab)](https://colab.research.google.com/drive/1-g4LJkbkHnIOKxcpcxlcXOaC4iU3yQ-6?usp=sharing)**
- **[ğŸŸ  Tokenization BPE (Colab)](https://colab.research.google.com/drive/1BcGWiBCv8ntFjtLbyPQzzsVNTeB-OWd4?usp=sharing)**
- **[ğŸŸ  Tokenizer Training (Colab)](https://colab.research.google.com/drive/1grpYJpb69-OqybpAsHfBsLRBIqC5gPjo?usp=sharing)**
- **[ğŸŸ  Tokenizing with Different Methods (Colab)](https://colab.research.google.com/drive/1necyJp2QExr0hVEH5X5vKhpPTZt277Lq?usp=sharing)**
- **[ğŸŸ  Persian BPE Tokenizer (Colab)](https://colab.research.google.com/drive/1fbiNoPIsGN8lymEXBvH63nKqNHYh_AG5?usp=sharing)**
- **[ğŸŸ  Persian Gemma Tokenizer (Colab)](https://colab.research.google.com/drive/1hqWGJQZKctOPk25zSFkfn5WLMmtbouJI?usp=sharing)**
- **[ğŸŸ  Train Llama Tokenizer (Colab)](https://colab.research.google.com/drive/1io3lfNNz7cJfH_SO9eRqJxWufG3W-5AK?usp=sharing)**

#### ğŸ¤— Persian Tokenizers:
- **[PersianBPETokenizer](https://huggingface.co/mshojaei77/PersianBPETokenizer)** - BPE tokenizer optimized for Persian text
- **[PersianGemmaTokenizerFast](https://huggingface.co/mshojaei77/PersianGemmaTokenizerFast)** - Fast tokenizer for Persian Gemma models
- **[PersianWordPieceTokenizer](https://huggingface.co/mshojaei77/PersianWordPieceTokenizer)** - WordPiece tokenizer for Persian language
- **[PersianUnigramTokenizer](https://huggingface.co/mshojaei77/PersianUnigramTokenizer)** - Unigram-based tokenizer for Persian
- **[PersianLlamaTokenizerFast](https://huggingface.co/mshojaei77/PersianLlamaTokenizerFast)** - Fast tokenizer for Persian Llama models

### 2. [Embeddings](Tutorial/Embeddings.md)
Word2Vec, GloVe, BERT, contextual embeddings, semantic search, multimodal embeddings

#### ğŸ“„ Publications:
- **[Word Embeddings Deep Dive](https://medium.com/@mshojaei77/from-words-to-vectors-a-gentle-introduction-to-word-embeddings-eaadb1654778)**
- **[Contextual Embedding Guide](https://medium.com/@mshojaei77/beyond-one-word-one-meaning-contextual-embeddings-187b48c6fc27)**
- **[Sentence Embedding Techniques](https://medium.com/@mshojaei77/beyond-words-mastering-sentence-embeddings-for-semantic-nlp-dc852b1382ba)**

#### ğŸ’» Interactive Notebooks:
- **[ğŸŸ  Interactive Word2Vec Tutorial](https://colab.research.google.com/drive/1dVkCRF0RKWWSP_QQq79LHNYGhead14d0?usp=sharing)**
- **[ğŸŸ  Embedding Techniques (Colab)](https://colab.research.google.com/drive/1EsafsnpONd7VI2hlTRJ0PYjrTmvSTA8x?usp=sharing)**
- **[ğŸŸ  Pre-trained Embeddings (Colab)](https://colab.research.google.com/drive/1pPB-7ZIzyJ88SR83DqGUZKLHj4y4TAHy?usp=sharing)**
- **[ğŸŸ  Traditional Word Embedding (Colab)](https://colab.research.google.com/drive/1ufvWaTDL0lK2tyTwdRBnXouHIMjBiKBC?usp=sharing)**
- **[ğŸŸ  Train a Word2Vec Model (Colab)](https://colab.research.google.com/drive/1xxH3Ak6ycH6UITpFytac7JHEJTj__eiX?usp=sharing)**
- **[ğŸŸ  Word Embeddings (Colab)](https://colab.research.google.com/drive/1yu0JxtCn5cYBFeTrCPeheSG0p9zRnxYR?usp=sharing)**

### 3. [Neural Networks](Tutorial/Neural_Networks.md)
Backpropagation, activation functions, optimization, regularization, mixed precision training


### 4. [Traditional Language Models](Tutorial/Traditional_LMs.md)
N-gram models, RNNs, LSTMs, GRUs, sequence-to-sequence models, attention mechanisms

#### ğŸ“„ Publications:
- **[Understanding Language Models](https://medium.com/@mshojaei77/1ac0e05ca1f3)**

#### ğŸ’» Interactive Notebooks:
- **[ğŸŸ  Intro to Large Language Models (Colab)](https://colab.research.google.com/drive/1HGqq9dKb-JlAgw0gdUhSmTKf-0v9Xq1Y?usp=sharing)**
- **[ğŸŸ  Understanding Large Language Models (Colab)](https://colab.research.google.com/drive/1wmHSypXDmiAhb1SgjLZR2wJDRj34lb4L?usp=sharing)**

### 5. [Transformers](Tutorial/Transformers.md)
Self-attention, multi-head attention, positional encodings, decoder-only architecture

### 6. [Data Preparation](Tutorial/Data_Preparation.md)
Data collection, web scraping, cleaning, deduplication, quality assessment, synthetic data generation

#### ğŸ’» Interactive Notebooks:
- **[ğŸŸ  Dataset Merge (Colab)](https://colab.research.google.com/drive/1BT8o8mkD4iwMC9zxSlMvtTivLxHSvbDV?usp=sharing)**
- **[ğŸŸ  Dataset Merger Simple (Colab)](https://colab.research.google.com/drive/1eKw9gOqRanXntb1azv4bWOx7pIlvaMDn?usp=sharing)**
- **[ğŸŸ  Dataset Merger Speech (Colab)](https://colab.research.google.com/drive/1e_dIgQae3Hy-FJjObVbAG8gJHgbHPvUf?usp=sharing)**
- **[ğŸŸ  Noise Reduction Test (Colab)](https://colab.research.google.com/drive/10aCNn6ICV3J4MpYfP7RnK8q4qUBi65ZW?usp=sharing)**
- **[ğŸŸ  EEG Artifact Detection (Colab)](https://colab.research.google.com/drive/1DkJ3Yyfep9qGHDc9G245OgwIvCSlRCR9?usp=sharing)**

#### ğŸš€ Open Source Projects:
- **[AdvancedWebScraper](https://github.com/mshojaei77/AdvancedWebScraper)** - Comprehensive web scraping tool with versatile data extraction capabilities
- **[Prompt-Scraper](https://github.com/mshojaei77/Prompt-Scraper)** - Effortlessly collect and transform Midjourney prompts into LM datasets
- **[Youtube2Book](https://github.com/mshojaei77/Youtube2Book)** - Extract transcripts from YouTube videos and structure with AI
- **[Word-Frequency-Analyzer](https://github.com/mshojaei77/Word-Frequency-Analyzer)** - Analyze word frequency in monthly news data
- **[pytsetmc-api](https://github.com/mshojaei77/pytsetmc-api)** - Python client for Tehran Stock Exchange Market Center data retrieval
- **[langchain_crawler](https://github.com/mshojaei77/langchain_crawler)** - Web crawling implementation using LangChain

## ğŸ§ª Model Training & Fine-Tuning

### 7. [Pre-Training](Tutorial/Pre_Training.md)
Unsupervised pre-training, causal language modeling, distributed training, scaling laws

### 8. [Post-Training Datasets](Tutorial/Post_Training_Datasets.md)
Instruction datasets, chat templates, conversation formatting, synthetic data generation

#### ğŸ“„ Publications:
- **[RAG vs. CAG vs. Fine-Tuning: Which Brain Boost Does Your LLM Actually Need?](https://medium.com/@mshojaei77/rag-vs-cag-vs-fine-tuning-which-brain-boost-does-your-llm-actually-need-b1234567890a)**

#### ğŸ’» Interactive Notebooks:
- **[ğŸŸ  Persian SFT Formattings (Colab)](https://colab.research.google.com/drive/1S-LwgyO_bmS135nJmJxm1ZKVlpv9Acfv?usp=sharing)**
- **[ğŸŸ  CAG (Cache-Augmented Generation) (Colab)](https://colab.research.google.com/drive/1-EIO5M6zeQgTd715PKCk-XK9odfEgOZY?usp=sharing)**

### 9. [Supervised Fine-Tuning](Tutorial/Supervised_Fine_Tuning.md)
LoRA, QLoRA, PEFT, instruction tuning, domain adaptation, model merging

#### ğŸ“„ Publications:
- **[The LoRA Cookbook: Fine-Tuning Large Language Models for Everyone](https://medium.com/@mshojaei77/the-lora-cookbook-fine-tuning-large-language-models-for-everyone-a1234567890a)**

#### ğŸ’» Interactive Notebooks:
- **[ğŸŸ  Fine-tune Mistral-7b with QLoRA](https://colab.research.google.com/drive/1o_w0KastmEJNVwT5GoqMCciH-18ca5WS?usp=sharing)**
- **[ğŸŸ  LazyMergekit](https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing)**
- **[ğŸŸ  LazyAxolotl](https://colab.research.google.com/drive/1TsDKNo2riwVmU55gjuBgB1AXVtRRfRHW?usp=sharing)**
- **[ğŸŸ  AutoQuant](https://colab.research.google.com/drive/1b6nqC7UZVt8bx4MksX7s656GXPM-eWw4?usp=sharing)**
- **[ğŸŸ  Model Family Tree](https://colab.research.google.com/drive/1s2eQlolcI1VGgDhqWIANfkfKvcKrMyNr?usp=sharing)**
- **[ğŸŸ  ZeroSpace](https://colab.research.google.com/drive/1LcVUW5wsJTO2NGmozjji5CkC--646LgC)**
- **[ğŸŸ  AutoAbliteration](https://colab.research.google.com/drive/1RmLv-pCMBBsQGXQIM8yF-OdCNyoylUR1?usp=sharing)**
- **[ğŸŸ  AutoDedup](https://colab.research.google.com/drive/1o1nzwXWAa8kdkEJljbJFW1VuI-3VZLUn?usp=sharing)**
- **[ğŸŸ  Fine-tune LLMs with Axolotl (Colab)](https://colab.research.google.com/drive/134SeMeoVCT0Sh-iRHlJ6wb_JBApspbkN?usp=sharing)**
- **[ğŸŸ  OpenAI GPT-4o Fine-tuning (Colab)](https://colab.research.google.com/drive/12ZRobn4GHPHLWuefJ4JYoX3TEhwXBM-T?usp=sharing)**
- **[ğŸŸ  GRPO Fine-tune (Colab)](https://colab.research.google.com/drive/155cGUY1kLOtb7b0ycHdW7cZbaK3na856?usp=sharing)**
- **[ğŸŸ  Llama 1B GRPO Training (Colab)](https://colab.research.google.com/drive/15o_Grw4PGnVNj03uAaB2Juctil_ADy_g?usp=sharing)**
- **[ğŸŸ  Qwen GRPO Training (Colab)](https://colab.research.google.com/drive/18HV_LDfIEq5NUApKpduVGdLxTGaEmNDK?usp=sharing)**
- **[ğŸŸ  Mergekit (Colab)](https://colab.research.google.com/drive/19k6DRX3h2_s1J7VwQl3fJKx-q5jrd7a_?usp=sharing)**
- **[ğŸŸ  Merge Parameters (Colab)](https://colab.research.google.com/drive/1tPIPqKL_pUrxTst-7X59-EyXVCK-z6Rm?usp=sharing)**
- **[ğŸŸ  Gemma SFT (Colab)](https://colab.research.google.com/drive/1fF4iPcBDoq4W-8z1eq53dA4VcZcXqF_W?usp=sharing)**
- **[ğŸŸ  Gemma3 4B (Colab)](https://colab.research.google.com/drive/1AbHtKyeyuZSZBEwrAbgfTyc4Fee7smQB?usp=sharing)**
- **[ğŸŸ  Gemma3 4B Persian (Colab)](https://colab.research.google.com/drive/1ENgkVdgO9AOtBRFq0Vykctgazpk2wvcL?usp=sharing)**
- **[ğŸŸ  Gemma3 4B Persian v2 (Colab)](https://colab.research.google.com/drive/1fiSXbawfI-EMvntaV81ORDnjKDKZhzAl?usp=sharing)**
- **[ğŸŸ  Persian Gemma3 4B (Colab)](https://colab.research.google.com/drive/1gSeiaY5NcL51q0CZCbDCsPXt2DDhPFaS?usp=sharing)**
- **[ğŸŸ  Qwen2.5 7B Alpaca (Colab)](https://colab.research.google.com/drive/1GRl5QMsQL56pB4O49jnPr_KA0uxam02E?usp=sharing)**
- **[ğŸŸ  SFT (Supervised Fine-Tuning) (Colab)](https://colab.research.google.com/drive/1tdPUEUQb97HkNObhQD8YsJ1zy4sGAPjU?usp=sharing)**
- **[ğŸŸ  GGUF Maker (Colab)](https://colab.research.google.com/drive/1gw4QwKABzwJgVzs91_lEUW5R0y_GFz52?usp=sharing)**

### 10. [Preference Alignment](Tutorial/Preference_Alignment.md)
RLHF, DPO, reward modeling, Constitutional AI, safety evaluation

### 11. [Model Architectures](Tutorial/Model_Architecture_Variants.md)
Mixture of Experts, state space models, Mamba, RWKV, long context architectures

### 12. [Reasoning](Tutorial/Reasoning.md)
Chain-of-Thought, tree-of-thoughts, process reward models, test-time compute scaling

#### ğŸ“„ Publications:
- **[How AI Learns to Fix Own Mistakes](https://medium.com/@mshojaei77/how-ai-learns-to-fix-own-mistakes-a1234567890a)**

### 13. [Evaluation](Tutorial/Evaluation.md)
Benchmarking, MMLU, GSM8K, HumanEval, human evaluation, bias testing

## ğŸš€ Production & Deployment

### 14. [Quantization](Tutorial/Quantization.md)
Post-training quantization, quantization-aware training, GGUF, INT4/INT8 quantization

### 15. [Inference Optimization](Tutorial/Inference_Optimization.md)
Flash Attention, KV cache, speculative decoding, high-throughput inference

#### ğŸ“„ Publications:
- **[Understanding the Differences Between CPU, GPU, TPU, and LPU](https://medium.com/@mshojaei77/understanding-the-differences-between-cpu-gpu-tpu-and-lpu-a1234567890a)**

#### ğŸš€ Open Source Projects:
- **[vram-calculator](https://github.com/mshojaei77/vram-calculator)** - Calculate VRAM requirements for LLMs and recommend suitable GPUs

### 16. [Model Enhancement](Tutorial/Model_Enhancement.md)
Context window extension, model merging, knowledge distillation, continual learning

### 17. [Security & Responsible AI](Tutorial/Securing_LLMs.md)
OWASP LLM Top 10, prompt injection, jailbreaking, bias detection, privacy protection

### 18. [Running LLMs](Tutorial/Running_LLMs.md)
API integration, local deployment, production servers, streaming responses

#### ğŸ“„ Publications:
- **[Guide to Deploying Qwen 3 with vLLM on RunPod](https://medium.com/@mshojaei77/guide-to-deploying-qwen-3-with-vllm-on-runpod-a1234567890a)**

#### ğŸš€ Open Source Projects:
- **[ollama-desktop](https://github.com/mshojaei77/ollama-desktop)** - Powerful desktop application for interacting with local AI models
- **[ollama_gui](https://github.com/mshojaei77/ollama_gui)** - User-friendly Qt desktop application for Ollama backend
- **[SubTrans-Ollama](https://github.com/mshojaei77/SubTrans-Ollama)** - Simple tool for translating movie subtitles (.srt) files
- **[ChatGPT-Desktop-App](https://github.com/mshojaei77/ChatGPT-Desktop-App)** - Interactive desktop app with document uploads and conversation management
- **[OpenRouterChatApp](https://github.com/mshojaei77/OpenRouterChatApp)** - Simple chat application using OpenRouter API
- **[GPT-Translator](https://github.com/mshojaei77/GPT-Translator)** - Streamlit translation app using advanced language models
- **[Pdf-Finder-Telegram-bot](https://github.com/mshojaei77/Pdf-Finder-Telegram-bot)** - Search for book PDFs in Telegram bot
- **[healthcare-assistant](https://github.com/mshojaei77/healthcare-assistant)** - Healthcare chat interface for emotional support and stress analysis

## ğŸ¤– Applications & Systems

### 19. [RAG](Tutorial/RAG.md)
Retrieval Augmented Generation, vector databases, Graph RAG, conversational RAG

#### ğŸš€ Open Source Projects:
- **[ollama_rag](https://github.com/mshojaei77/ollama_rag)** - Fully local RAG system using Ollama and FAISS
- **[open-notebook](https://github.com/mshojaei77/open-notebook)** - AI-powered knowledge management and question-answering system
- **[TalkWithWeb](https://github.com/mshojaei77/TalkWithWeb)** - Customizable AI chatbot with personalized knowledge base
- **[DataSpeakGPT](https://github.com/mshojaei77/DataSpeakGPT)** - Read files and images and retrieve data for LLM
- **[Cortex](https://github.com/mshojaei77/Cortex)** - Advanced AI Deep Scholar Researcher Agent with RAG and Milvus integration
- **[RAG-Agent](https://github.com/mshojaei77/RAG-Agent)** - RAG implementation with LangChain and LangGraph libraries
- **[RAG_CAG_SFT](https://github.com/mshojaei77/RAG_CAG_SFT)** - Educational overview of RAG, Cache-Augmented Generation, and SFT techniques

### 20. [Agents](Tutorial/Agents.md)
Function calling, tool usage, multi-agent systems, autonomous task execution

#### ğŸš€ Open Source Projects:
- **[ReActMCP](https://github.com/mshojaei77/ReActMCP)** - Reactive MCP client for real-time web search insights **(141â­)**
- **[EasyMCP](https://github.com/mshojaei77/EasyMCP)** - Beginner-friendly client for Model Context Protocol
- **[Groogle](https://github.com/mshojaei77/Groogle)** - Groq + Google integration for enhanced search capabilities
- **[GoogleGPT](https://github.com/mshojaei77/GoogleGPT)** - Combine Google search with ChatGPT capabilities
- **[simple_function_calling](https://github.com/mshojaei77/simple_function_calling)** - Beginner tutorial on connecting LLMs to external tools
- **[SuperAgent](https://github.com/mshojaei77/SuperAgent)** - Advanced agent implementation
- **[SuperNova-Desktop](https://github.com/mshojaei77/SuperNova-Desktop)** - Desktop agent application

### 21. [Multimodal](Tutorial/Multimodal.md)
Vision-language models, text-to-image generation, audio processing, document understanding

#### ğŸ’» Interactive Notebooks:
- **[ğŸŸ  Whisper Turbo (Colab)](https://colab.research.google.com/drive/1yf3WiqyjpO9LcC0LV48CWotOl4Sv4ngQ?usp=sharing)**
- **[ğŸŸ  Whisper Turbo FP32 Async (Colab)](https://colab.research.google.com/drive/1xS2bMCt6acvaWdeT_r8gtnole3bSFjG3?usp=sharing)**
- **[ğŸŸ  Maestro Qwen2.5 VL JSON Extraction (Colab)](https://colab.research.google.com/drive/1Ia_rCRcVUqBcKGNS_8HTYtzy3OZ9Mo1k?usp=sharing)**
- **[ğŸŸ  XTTS Test on Long Text (Colab)](https://colab.research.google.com/drive/1xXOnvsuTqdZiAb9Mzqpe_MRBD4FlbCr2?usp=sharing)**

#### ğŸš€ Open Source Projects:
- **[Text2Prompt2Image](https://github.com/mshojaei77/Text2Prompt2Image)** - Flask app using Mixtral-8x7B & Playground-v2 for text-to-image generation
- **[flux_local](https://github.com/mshojaei77/flux_local)** - Lightweight toolkit for running FLUX.1-schnell text-to-image models locally

### 22. [LLMOps](Tutorial/LLMOps.md)
Model versioning, CI/CD pipelines, monitoring, deployment strategies, cost optimization

---

# ğŸ“Š Datasets & Resources

## ğŸ‡®ğŸ‡· Persian Language Resources

### ğŸ“š Persian Language Datasets:
- **[PersianCorpus_merged](https://huggingface.co/mshojaei77/PersianCorpus_merged)** - Massive Persian corpus with 14.7M records **(38 downloads)**
- **[PersianTelegramChannels](https://huggingface.co/mshojaei77/PersianTelegramChannels)** - Persian Telegram channels dataset with 12.1k records **(74 downloads)**
- **[persian-document-corpus](https://huggingface.co/mshojaei77/persian-document-corpus)** - Persian document corpus with 13.1k records **(31 downloads)**
- **[persian_blogs](https://huggingface.co/mshojaei77/persian_blogs)** - Persian blog posts dataset with 27.4k records **(28 downloads)**
- **[persian-tweets-2024](https://huggingface.co/mshojaei77/persian-tweets-2024)** - Persian tweets from 2024 with 900 records **(23 downloads)**
- **[persian-search-queries](https://huggingface.co/mshojaei77/persian-search-queries)** - Persian search queries dataset with 1.31k records **(27 downloads)**

### ğŸ“Š Persian Instruction Datasets:
- **[Persian_sft](https://huggingface.co/mshojaei77/Persian_sft)** - Persian supervised fine-tuning dataset with 681k records **(59 downloads)**
- **[Persian_sft_jsonl](https://huggingface.co/mshojaei77/Persian_sft_jsonl)** - Persian SFT in JSONL format with 681k records **(26 downloads)**
- **[Persian_sft_QA](https://huggingface.co/mshojaei77/Persian_sft_QA)** - Persian SFT Q&A format with 681k records **(33 downloads)**
- **[merged_persian_alpaca](https://huggingface.co/mshojaei77/merged_persian_alpaca)** - Persian Alpaca-style instruction dataset with 527k records **(21 downloads)**
- **[merged_persian_sharegpt](https://huggingface.co/mshojaei77/merged_persian_sharegpt)** - Persian ShareGPT format dataset with 527k records **(17 downloads)**
- **[Persian_lmsys_QA](https://huggingface.co/mshojaei77/Persian_lmsys_QA)** - Persian LMSYS Q&A dataset with 5.43k records **(59 downloads)**
- **[alpaca_persian_telegram](https://huggingface.co/mshojaei77/alpaca_persian_telegram)** - Persian Alpaca with Telegram data, 1k records **(17 downloads)**

### ğŸ“Š Persian Evaluation Datasets:
- **[multiple-choice-persian-eval](https://huggingface.co/mshojaei77/multiple-choice-persian-eval)** - Persian multiple-choice evaluation dataset with 364 records **(20 downloads)**
- **[SCED](https://huggingface.co/mshojaei77/SCED)** - Specialized evaluation dataset with 32 records **(18 downloads)**

### ğŸµ Persian Audio Datasets:
- **[persian_tts_merged](https://huggingface.co/mshojaei77/persian_tts_merged)** - Persian TTS dataset with 82.2k records **(60 downloads)**
- **[farsi_asr_merged](https://huggingface.co/mshojaei77/farsi_asr_merged)** - Persian ASR dataset **(12 downloads, Private)**

## ğŸŒ Multi-Language & Specialized Datasets

### ğŸŒ Multi-Language Instruction Datasets:
- **[Dolly_Alpaca_Lmsys](https://huggingface.co/mshojaei77/Dolly_Alpaca_Lmsys)** - Merged instruction dataset with 1.07M records **(26 downloads)**
- **[merged_mental_health_dataset](https://huggingface.co/mshojaei77/merged_mental_health_dataset)** - Mental health support dataset with 868k records **(26 downloads)**

### ğŸ“š Educational Datasets:
- **[ielts-practice-sentences](https://huggingface.co/mshojaei77/ielts-practice-sentences)** - IELTS practice sentences with 45.7k records **(24 downloads)**

### ğŸ¨ Creative Datasets:
- **[Midjourney-Art-Prompts](https://huggingface.co/mshojaei77/Midjourney-Art-Prompts)** - Curated collection of Midjourney art prompts **(3 records)**

---

# ğŸ¤– Persian LLM Models

## ğŸ”¥ Featured Models:
- **[gemma-3-4b-persian-v0](https://huggingface.co/mshojaei77/gemma-3-4b-persian-v0)** - Persian fine-tuned Gemma-3 4B model **(1.74K downloads)**
- **[gemma-2-2b-fa-v2](https://huggingface.co/mshojaei77/gemma-2-2b-fa-v2)** - Persian Gemma-2 2B model v2 **(21 downloads)**
- **[Gemma-2-2b-fa](https://huggingface.co/mshojaei77/Gemma-2-2b-fa)** - Persian Gemma-2 2B model **(13 downloads)**
- **[persian_phi-3](https://huggingface.co/mshojaei77/persian_phi-3)** - Persian fine-tuned Phi-3 model **(Private)**

## ğŸ¯ Specialized Variants:
- **[gemma-3-4b-persian-lora-adaptors](https://huggingface.co/mshojaei77/gemma-3-4b-persian-lora-adaptors)** - LoRA adapters for Persian Gemma-3 **(9 downloads)**
- **[gemma-3-4b-persian-v0-abliterated](https://huggingface.co/mshojaei77/gemma-3-4b-persian-v0-abliterated)** - Abliterated version for uncensored responses **(6 downloads)**
- **[gemma-3-4b-persian-v0-abliterated-Q8_0-GGUF](https://huggingface.co/mshojaei77/gemma-3-4b-persian-v0-abliterated-Q8_0-GGUF)** - Quantized GGUF format **(11 downloads)**

---

# ğŸŒŸ Community & Learning Resources

## ğŸ“š Learning Platforms

### ğŸ¯ Curated Collections:
- **[Awesome-AI](https://github.com/mshojaei77/Awesome-AI)** - Best AI resources, tools, samples, and demos **(124â­)**
- **[Awesome-Prompts](https://github.com/mshojaei77/Awesome-Prompts)** - Ready-to-use prompts for productivity and creativity

### ğŸ“š Educational Resources:
- **[LLMs-Journey](https://github.com/mshojaei77/LLMs-Journey)** - Progress tracking with code, projects, and notes
- **[ML-Journey](https://github.com/mshojaei77/ML-Journey)** - Machine Learning journey with hands-on projects
- **[Python-Course](https://github.com/mshojaei77/Python-Course)** - Teaching materials from Kazerun University course



---

# ğŸ“Š Impact & Metrics

| **Platform** | **Metric** | **Value** |
|-------------|------------|-----------|
| ğŸ¤— Hugging Face | Model Downloads | 1.8K+ |
| ğŸ¤— Hugging Face | Dataset Downloads | 500+ |
| ğŸ™ GitHub | Total Stars | 600+ |
| ğŸ“„ Medium | Article Views | 100K+ |
| ğŸŸ  Colab | Notebook Runs | 10K+ |
| ğŸ‘¥ GitHub | Followers | 184 |
| ğŸ¤— Hugging Face | Followers | 52 |

---

# ğŸ”— Connect

- **ğŸ“§ Email:** [shojaei.dev@gmail.com](mailto:shojaei.dev@gmail.com)
- **ğŸ’¼ LinkedIn:** [mshojaei77](https://www.linkedin.com/in/mshojaei77)
- **ğŸ™ GitHub:** [mshojaei77](https://github.com/mshojaei77)
- **ğŸ¤— Hugging Face:** [mshojaei77](https://huggingface.co/mshojaei77)
