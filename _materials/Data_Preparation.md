---
title: "Data Preparation for LLMs: Cleaning Guide"
nav_order: 7
parent: Tutorials
layout: default
---

# Data Preparation for LLMs ðŸ§¹: Garbage In, Garbage Out â€“ Clean Text Feast
Master dataset cleaning guide for training powerful large language models.

## Collecting Data for LLMs
- Web scraping, books, code repositories â€“ gather diverse sources.
- Aim for variety to build robust models.

## Cleaning Datasets
- Deduplicate, filter out junk and noise.
- Normalize text: Lowercase, remove artifacts.

## Curating High-Quality Data
- Annotate for tasks, quality assurance checks.
- Push to Hugging Face Hub for sharing.

## Why Data Prep is Crucial
Bad data kills models! What's your go-to data cleaning hack? Drop it! ðŸ“Š

## My Data Prep Notes
- [Medium: Data Preparation Guide](https://medium.com/@mshojaei77/data-preparation-for-large-language-models-a-practical-guide-5a0b3b2b2f0e)
- [Colab: Data Hacks](https://colab.research.google.com/drive/1y0KnCFZvGVf_odSfcNAws6kcDD7HsI0L?usp=sharing)

## Top Data Preparation Resources
- [Hugging Face Datasets](https://huggingface.co/docs/datasets/en/index)
- [OpenWebText](https://skylion007.github.io/OpenWebTextCorpus/)
- [The Pile Paper](https://arxiv.org/abs/2101.00027)
- [RedPajama Blog](https://together.ai/blog/redpajama-data-v2)
- [Dolma Paper](https://arxiv.org/abs/2402.00159)

Keywords: data preparation for LLMs, dataset cleaning guide, LLM training data, AI data curation, text normalization techniques
