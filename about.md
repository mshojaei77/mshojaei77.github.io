# Mohammad Shojaei
*Machine Learning Engineer ‚Äì Large Language Models & NLP*

<p align="center">
üìß shojaei.dev@gmail.com | <a href="https://www.linkedin.com/in/mshojaei77">LinkedIn</a> | <a href="https://github.com/mshojaei77">GitHub</a> | <a href="https://huggingface.co/mshojaei77">Hugging Face</a>
</p>

---

## Summary
Results-driven Machine Learning Engineer with over two years of experience designing, fine-tuning, and deploying LLM-powered products across finance, real estate, and healthcare. Specialized in Retrieval-Augmented Generation (RAG), parameter-efficient fine-tuning (LoRA/QLoRA), and inference optimization. Proven ability to reduce infrastructure costs by 35%, achieve sub-250ms p95 latency, and increase user engagement by 40%.

---

## Core Competencies
- **LLM Development:** GPT-style Models (Gemma, Phi, Llama), Instruction & Alignment Tuning (SFT, RLHF), PEFT (LoRA, QLoRA)
- **RAG & Vector Search:** Qdrant, Milvus, Approximate Nearest Neighbor (ANN) Search, Re-ranking, Custom Chunking
- **Inference Optimization:** Quantization (AWQ, GGUF), KV-Cache, Speculative Decoding, Throughput Tuning
- **MLOps & Deployment:** Docker, FastAPI, Uvicorn, Hugging Face Hub, LangServe
- **General:** Python, SQL, AWS, Runpod, Git, Agile Methodologies

---

## Professional Experience

**No Limits Market Ltd.**, Remote ‚Äì Dubai, UAE
*LLM Engineer*, January 2025 ‚Äì Present
- Architected a RAG-based financial research platform serving over 50 analysts, reducing research time by 45%.
- Deployed AWQ-quantized models with optimized batching, achieving a 35% cost reduction and sub-250ms p95 latency.
- Automated JSON-schema report generation via structured LLM outputs, increasing analyst throughput by 60%.
- Implemented a CI/CD pipeline with automated evaluation metrics (perplexity, factual consistency), maintaining a 95%+ pass rate.

**Owlio**, Remote ‚Äì Turin, IT
*AI Engineer*, September 2024 ‚Äì January 2025
- Designed an educational AI agent using RAG and fine-tuned LLMs to convert passive lecture content into interactive learning experiences.
- Engineered custom chunking strategies for video transcript processing, optimizing retrieval accuracy for educational content.
- Implemented a token-based caching system that reduced GPT API costs by 40% while maintaining response quality.
- Built automated evaluation pipelines to measure RAG performance, content accuracy, and student engagement metrics.

**Real-Estate Startup**, Remote ‚Äì Moscow, RU
*Generative AI Engineer (Contract)*, May 2024 ‚Äì Present
- Fine-tuned a multilingual LLM using LoRA with domain-specific datasets, achieving 90% accuracy in handling over 50,000 monthly queries.
- Integrated Speech-to-Text/Text-to-Speech microservices via FastAPI to enable 24/7 automated client interaction.
- Developed a comprehensive evaluation framework to measure coherence, relevance, and safety, maintaining over 85% performance across all KPIs.
- Reduced safety incidents to less than 1% through systematic prompt engineering and content filtering.

**Alpha Neuroscience Co.**, Remote ‚Äì Tehran, IR
*Machine Learning Engineer*, May 2023 ‚Äì April 2024
- Developed an EEG artifact detection system using 1D-CNN and Transformer architectures, achieving a 70% improvement in accuracy.
- Built and deployed a PyQt5 desktop application to over 200 medical technicians, reducing per-patient review time by 15 minutes.
- Implemented a RAG-powered clinical assistant that decreased clinician query response time by 50% and improved diagnostic precision by 18 percentage points.
- Collaborated with medical professionals to validate model outputs and ensure clinical compliance.

*Previous Role:* Freelance AI & Generative AI Consultant (October 2023 ‚Äì January 2025)

---

## Open-Source Contributions & Leadership
- **Hugging Face Impact:** Published 12 Persian LLMs and 21 datasets, accumulating over 100,000 downloads.
- **ReActMCP (140 ‚≠ê):** Developed a reactive agent framework enabling real-time web search capabilities.
- **Ollama-Desktop & Ollama-RAG (60 ‚≠ê):** Created a local GUI and FAISS-powered RAG toolkit for offline LLM deployment.
- **Community Leadership:** Delivered technical workshops on LLM implementation and was recognized as a Hugging Face Community Leader.

---

## Education
**Bachelor of Science, Computer Engineering** ‚Äî University of Bam, *May 2024*

---

## Professional Certifications
- CS224N: Natural Language Processing with Deep Learning ‚Äì Stanford University, 2024
- LangChain for LLM Application Development ‚Äì DeepLearning.AI, 2024
- Machine Learning Specialization ‚Äì DeepLearning.AI, 2024
- Harvard CS50P: Introduction to Programming with Python ‚Äì Harvard University, 2023

---

## Technical Expertise
- **Languages & Frameworks:** Python, PyTorch, Transformers, JAX, PEFT, bitsandbytes, FlashAttention, FastAPI, LangChain, LangGraph
- **Data & ML Infrastructure:** Vector Databases (FAISS, Milvus, Qdrant), RAG, KV-Cache, Quantization (GPTQ, AWQ)
- **MLOps & Deployment:** Docker, GitHub Actions, CI/CD, Monitoring, AWS, GCP, MLOps, LLMOps
- **AI Techniques:** RLHF, Prompt Engineering, Agent Development, Model Fine-tuning, Inference Optimization


